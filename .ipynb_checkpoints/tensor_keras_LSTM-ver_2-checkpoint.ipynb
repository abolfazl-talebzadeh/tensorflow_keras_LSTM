{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8lpVdnId3iYM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "# from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "VSLcswUI3iYP"
   },
   "outputs": [],
   "source": [
    "politifact = pd.read_json(r'./data/politifact.json')\n",
    "snopes = pd.read_json(r'./data/snopes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "owxJjfnX3iYQ"
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "poli_cols = politifact.columns.to_list()\n",
    "snop_cols = snopes.columns.to_list()\n",
    "\n",
    "# poli_row_count, poli_col_count = politifact.shape\n",
    "# snop_row_count, snop_col_count = snopes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "2xM1yD6v3iYQ"
   },
   "outputs": [],
   "source": [
    "common_cols = set(poli_cols) & set(snop_cols)\n",
    "\n",
    "td = pd.concat([snopes[list(common_cols)], politifact[list(common_cols)]])\n",
    "td = td.reindex(columns = ['doc', 'claim', 'factchecker', 'url', 'sources', 'topic', 'published' ,'label' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "tn7FY5DF3iYR"
   },
   "outputs": [],
   "source": [
    "\n",
    "td['label'] = td['label'].map({\n",
    "    'Correct Attribution':0,\n",
    "    'False':1,\n",
    "    'Labeled Satire':2,\n",
    "    'Legend':3,\n",
    "    'Lost Legend':4,\n",
    "    'Misattributed':5,\n",
    "    'Miscaptioned':6,\n",
    "    'Mixture':7,\n",
    "    'Mostly False':8,\n",
    "    'Mostly True':9,\n",
    "    'Outdated':10,\n",
    "    'Research In Progress':11,\n",
    "    'Scam':12,\n",
    "    'True':13,\n",
    "    'Unproven':14,\n",
    "    'barely-true':15,\n",
    "    'false':1,\n",
    "    'full-flop':16,\n",
    "    'half-flip':17,\n",
    "    'half-true':18,\n",
    "    'mostly-true':19,\n",
    "    'no-flip':20,\n",
    "    'pants-fire':21,\n",
    "    'true':13}\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBX7czZ43iYR",
    "outputId": "71859cfa-7ca1-4da8-cf57-e55ac9182294"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:09<00:00, 27.04s/it]\n"
     ]
    }
   ],
   "source": [
    "mt = {\n",
    "        '\\n':\" \",\n",
    "        \"'\":None,\n",
    "        '\"':None,\n",
    "        '“':None,\n",
    "        '”':None,\n",
    "        '’':None,\n",
    "        '‘':None\n",
    "    }\n",
    "for n in range(10):\n",
    "    mt[str(n)]=None\n",
    "\n",
    "for x in string.punctuation:\n",
    "    mt[x]=None\n",
    "cols = td.columns.to_list()\n",
    "cols.remove('label')\n",
    "\n",
    "# cleaning the first file\n",
    "for col in tqdm(cols):\n",
    "    for indx, x in enumerate(td[col]):\n",
    "        try:\n",
    "            td.loc[indx,col] = (x.translate(x.maketrans(mt))).lower()\n",
    "        except:\n",
    "            if x==None:\n",
    "                td.loc[indx,col] = \"\"\n",
    "            elif type(x) == list:\n",
    "                p = \" \".join(str(z) for z in x)\n",
    "                td.loc[indx,col] = p.translate(p.maketrans(mt)).lower()\n",
    "            else:\n",
    "                print(f\"column:{col}\\trow:{indx}\\tvalue: {x} is invalid\\tvalue type: {type(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "VBh43NDF3iYT"
   },
   "outputs": [],
   "source": [
    "td = td.dropna(subset=['doc','claim','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "jCUtLNtr3iYU"
   },
   "outputs": [],
   "source": [
    "one_hot_prep = [one_hot(series['claim']+' '+ series['doc'],10000) for _, series in td.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Avb_FXSq_jcE",
    "outputId": "e4e13772-e7a3-45ef-e7e2-8cc4bce89608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6955\n"
     ]
    }
   ],
   "source": [
    "temp = [len(x) for x in one_hot_prep]\n",
    "print(max(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "CPyK5DXF_wxJ"
   },
   "outputs": [],
   "source": [
    "sent_len = 300\n",
    "embedded_docs = pad_sequences(one_hot_prep,padding='post',truncating='post',maxlen=sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "E7T2E-9CBChI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 300, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, 300, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 22)                2222      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,082,622\n",
      "Trainable params: 5,082,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embedding_vector_fetures = 64\n",
    "# vocab_size = 5000\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size,embedding_vector_fetures,input_length= sent_len))\n",
    "# model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))#LSTM(100))\n",
    "# model.add(Dense(24, activation = 'softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "vocab_size=50000\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length= sent_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(22, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,_ = td.shape\n",
    "\n",
    "# y = td['label']\n",
    "# new_y = np.zeros((x,24))\n",
    "\n",
    "# for i,r in enumerate(y):\n",
    "#     try:\n",
    "#         new_y[i][int(r)]=1\n",
    "#     except:\n",
    "#         print(i, y[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQJqrcPRDCnf",
    "outputId": "0d7a5546-8fa0-4ea3-c0bf-6c564e049c44"
   },
   "outputs": [],
   "source": [
    "final_x = np.array(embedded_docs)\n",
    "final_y = np.array(td['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17838, 300) (4460, 300) (17838,) (4460,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(final_x, final_y, test_size = 0.2, random_state = 42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "final_y_train = tf.keras.utils.to_categorical(y_train, num_classes=22)\n",
    "final_y_test = tf.keras.utils.to_categorical(y_test, num_classes=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17838, 300), (17838, 22), (4460, 300), (4460, 22))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, final_y_train.shape,x_test.shape,final_y_test.shape\n",
    "# print(final_y_train.shape, final_y_test.shape)\n",
    "# print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "558/558 [==============================] - 115s 200ms/step - loss: 2.1209 - accuracy: 0.2615 - val_loss: 2.0834 - val_accuracy: 0.2661\n",
      "Epoch 2/10\n",
      "558/558 [==============================] - 112s 200ms/step - loss: 2.0741 - accuracy: 0.2629 - val_loss: 2.0820 - val_accuracy: 0.2643\n",
      "Epoch 3/10\n",
      "558/558 [==============================] - 111s 200ms/step - loss: 2.0212 - accuracy: 0.2785 - val_loss: 2.1236 - val_accuracy: 0.2247\n",
      "Epoch 4/10\n",
      "558/558 [==============================] - 112s 200ms/step - loss: 1.9491 - accuracy: 0.2983 - val_loss: 2.1972 - val_accuracy: 0.2049\n",
      "Epoch 5/10\n",
      "558/558 [==============================] - 111s 200ms/step - loss: 1.8887 - accuracy: 0.3209 - val_loss: 2.2498 - val_accuracy: 0.2090\n",
      "Epoch 6/10\n",
      "558/558 [==============================] - 111s 200ms/step - loss: 1.8405 - accuracy: 0.3239 - val_loss: 2.3091 - val_accuracy: 0.1982\n",
      "Epoch 7/10\n",
      "558/558 [==============================] - 112s 200ms/step - loss: 1.7988 - accuracy: 0.3331 - val_loss: 2.3486 - val_accuracy: 0.2054\n",
      "Epoch 8/10\n",
      "558/558 [==============================] - 112s 201ms/step - loss: 1.7615 - accuracy: 0.3351 - val_loss: 2.4268 - val_accuracy: 0.2009\n",
      "Epoch 9/10\n",
      "558/558 [==============================] - 112s 200ms/step - loss: 1.7248 - accuracy: 0.3411 - val_loss: 2.4894 - val_accuracy: 0.1969\n",
      "Epoch 10/10\n",
      "558/558 [==============================] - 112s 200ms/step - loss: 1.6987 - accuracy: 0.3413 - val_loss: 2.5255 - val_accuracy: 0.1888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb87e19a7c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, final_y_train, batch_size=32, epochs=10, validation_data=(x_test,final_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 4s 32ms/step - loss: 2.5255 - accuracy: 0.1888\n",
      "0.1887892335653305 2.5254507064819336\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test,final_y_test)\n",
    "print(accuracy,loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
